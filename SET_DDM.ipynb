{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a drift diffusion model to SET data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs & thoughs\n",
    "* Load pupil data\n",
    "* Integrate pupil pattern (lin, quad, lin-quad) as predictor in regression -> http://ski.clps.brown.edu/hddm_docs/tutorial_python.html#fitting-regression-models\n",
    "* Better explanation of regression (just do `m = hddm.models.HDDMRegressor(data, 'v ~ BOLD')`) -> http://ski.clps.brown.edu/hddm_docs/howto.html#estimate-a-regression-model\n",
    "* Include within-subjects effects using patsy package -> http://ski.clps.brown.edu/hddm_docs/tutorial_python.html#within-subject-effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems and solutions\n",
    "* `ValueError: Buffer dtype mismatch, expected 'double' but got 'long'` -> rts must be coded in seconds (not miliseconds)\n",
    "* `KeyError: 'rt'` -> column names must match up with example here: http://ski.clps.brown.edu/hddm_docs/tutorial_python.html\n",
    "* `ZeroProbability: Stochastic wfpt(0span).8.0's value is outside its support, or it forbids its parents' current values.` -> remove all subjects for which it throws this error\n",
    "* `Could not generate output statistics for a_subj(1span).12.0` -> number of samples must greater than number of burn. e.g., model.sample(300, burn=300) does NOT work, but model.sample(500, burn=300) works!\n",
    "* `AssertionError: Step-out procedure failed` -> loaded `Train` data instead of `Exp` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of HDDM parameters\n",
    "see also http://ski.clps.brown.edu/hddm_docs/methods.html\n",
    "\n",
    "* v -> The speed with which the accumulation process approaches one of the two boundaries is called drift-rate v and represents the relative evidence for or against a particular response.\n",
    "* a -> The distance between the two boundaries (i.e. threshold a) influences how much evidence must be accumulated until a response is executed. \n",
    "* t -> Response time, however, is not solely comprised of the decision making process – perception, movement initiation and execution all take time and are lumped in the DDM by a single non-decision time parameter t.\n",
    "* z -> The model also allows for a prepotent bias z affecting the starting point of the drift process relative to the two boundaries.\n",
    "* sv-> inter-trial variability in drift-rate\n",
    "* st -> inter-trial variability in non-decision time\n",
    "* sz -> inter-trial variability in starting-point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.remove('/usr/local/anaconda/lib/python2.7/site-packagedfgdfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\SETDDM\\lib\\site-packages\\IPython\\parallel.py:13: ShimWarning: The `IPython.parallel` package has been deprecated since IPython 4.0. You should import from ipyparallel instead.\n",
      "  \"You should import from ipyparallel instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from first import first\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import hddm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "file_dir = base_dir + \"/subj_files/databoth/raw_data\"\n",
    "n_subj = 61  # there are 61 in total\n",
    "preprocess_data = False\n",
    "n_burn = 200  # traces look good after about 1000\n",
    "n_sample = 800 + n_burn  # n_samples must be > n_burn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'hddm/hddm_all_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-059ab97da22b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hddm/hddm_all_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mexclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m303\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m309\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m320\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SETDDM\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SETDDM\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SETDDM\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SETDDM\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\SETDDM\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'hddm/hddm_all_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Read in and clean data\n",
    "if preprocess_data:\n",
    "    files = glob.glob(file_dir + \"/seq*SET*.csv\")[:n_subj]\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        # Drop unncessary rows and columns\n",
    "        data_file = pd.read_csv(file, low_memory=False)\n",
    "        data_file = data_file[data_file.TrainorExp != \"Train\"]\n",
    "        data_file = data_file[[\"Subject\", \"TrialId\", \"CRESP\", \"RESP\", \"ACC\", \"RT\", \"Category\", \"SETornoSET\"]]\n",
    "\n",
    "        # Add all subjects into one file\n",
    "        all_data = all_data.append(data_file)\n",
    "\n",
    "    # Remove eye tracking data\n",
    "    grouped = all_data.groupby([\"Subject\", \"TrialId\"], as_index=False)\n",
    "    all_data = grouped.agg(first)\n",
    "\n",
    "    all_data['RT'] = all_data['RT'] / 1000\n",
    "    all_data = all_data.rename(columns={\"Subject\": \"subj_idx\", \"RT\": \"rt\"})\n",
    "\n",
    "    all_data.to_csv(\"hddm/hddm_all_data.csv\")\n",
    "    \n",
    "else:\n",
    "    all_data = pd.read_csv(\"hddm/hddm_all_data.csv\")\n",
    "    \n",
    "exclude = [8, 19, 33, 303, 309, 320]\n",
    "all_data = all_data[np.logical_not(all_data.subj_idx.isin(exclude))]\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_data = pd.read_csv(\"ppgs234.csv\")\n",
    "ppg_data = ppg_data[[\"Subject\", \"lin_b\", \"qua_b\", \"ppg_cont\", \"ppg\"]]\n",
    "ppg_data = ppg_data.rename(columns={\"Subject\": \"subj_idx\"})\n",
    "ppg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(all_data, ppg_data, on=\"subj_idx\")\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for ACCURACY MODEL\n",
    "acc_data = all_data.copy()\n",
    "acc_data = acc_data.rename(columns={\"ACC\": \"response\"})\n",
    "acc_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RT distributions\n",
    "acc_data = hddm.utils.flip_errors(acc_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, xlabel='RT', ylabel='count', title='RT distributions')\n",
    "for i, subj_data in acc_data.groupby('subj_idx'):\n",
    "    subj_data.rt.hist(bins=20, histtype='step', ax=ax)\n",
    "plt.savefig('hddm/acc_rt_hist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Span decreases drift rate, but does not affect decision threshold\n",
    "*a ~ Category & v ~ Category*\n",
    "\n",
    "The decision boundaries have the same distance to each other in each span condition. Participants make decisions equally carefully in all span conditions.\n",
    "\n",
    "The drift rate is reduced in higher span conditions. It takes participants longer to gather the required evidence, in accordance with our memory search account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic accuracy model\n",
    "span_model = hddm.HDDM(acc_data,\n",
    "                          depends_on={'a': 'Category', 'v': 'Category'},\n",
    "                          p_outlier=0.05)\n",
    "span_model.find_starting_values()\n",
    "span_model.sample(n_sample, burn=n_burn)\n",
    "span_model.get_traces().to_csv(\"hddm/span_traces.csv\")\n",
    "span_model.gen_stats().to_csv('hddm/span_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create accuracy model with bias and sds\n",
    "# acc_model_comp = hddm.HDDM(acc_data,\n",
    "#                            depends_on={'a': 'Category', 'v': 'Category'},\n",
    "#                            include=('z', 'sv', 'st', 'sz'),\n",
    "#                            p_outlier=0.05)\n",
    "# acc_model_comp.find_starting_values()\n",
    "# acc_model_comp.sample(n_sample, burn=n_burn)\n",
    "# acc_model_comp.get_traces().to_csv(\"hddm/acc_traces_comp.csv\")\n",
    "# acc_model_comp.gen_stats().to_csv('hddm/acc_stats_comp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(span_model.nodes_db.node[['a(0span)', 'a(1span)', 'a(2span)', 'a(3span)']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/span_model_a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(span_model.nodes_db.node[['v(0span)', 'v(1span)', 'v(2span)', 'v(3span)']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/span_model_v.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_model.plot_posterior_predictive(figsize=(14, 10))\n",
    "plt.savefig('hddm/span_posterior_predictive.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Pupil pattern ...\n",
    "*a ~ ppg & v ~ ppg* (ppg groups) and *a ~ ppg_cont & v ~ ppg_cont* (continuous ppg measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic accuracy model\n",
    "ppg_model = hddm.HDDM(acc_data,\n",
    "                      depends_on={'a': 'ppg', 'v': 'ppg'},\n",
    "                      p_outlier=0.05)\n",
    "ppg_model.find_starting_values()\n",
    "ppg_model.sample(n_sample, burn=n_burn)\n",
    "ppg_model.get_traces().to_csv(\"hddm/ppg_traces.csv\")\n",
    "ppg_model.gen_stats().to_csv('hddm/ppg_traces.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(ppg_model.nodes_db.node[['a(linear)', 'a(inverse-u)']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/ppg_a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(ppg_model.nodes_db.node[['v(linear)', 'v(inverse-u)']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/ppg_v.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accuracy model with ppg\n",
    "ppg_cont_model = hddm.models.HDDMRegressor(acc_data,\n",
    "                                           ['a ~ ppg_cont', 'v ~ ppg_cont'],\n",
    "                                           p_outlier=0.05)\n",
    "ppg_cont_model.find_starting_values()\n",
    "ppg_cont_model.sample(n_sample, burn=n_burn)\n",
    "ppg_cont_model.get_traces().to_csv(\"hddm/ppg_cont_traces.csv\")\n",
    "ppg_cont_model.gen_stats().to_csv('hddm/ppg_cont_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(ppg_cont_model.nodes_db.node[['a_ppg_cont', 'v_ppg_cont']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/ppg_cont.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Span and pupil pattern\n",
    "*a ~ ppg_cont * span & v ~ ppg_cont * span*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with span and ppg\n",
    "ppg_span_model = hddm.models.HDDMRegressor(acc_data,\n",
    "                                           ['a ~ ppg_cont*Category', 'v ~ ppg_cont*Category'],\n",
    "                                           p_outlier=0.05)\n",
    "ppg_span_model.find_starting_values()\n",
    "ppg_span_model.sample(n_sample, burn=n_burn)\n",
    "ppg_span_model.get_traces().to_csv(\"hddm/ppg_span_traces.csv\")\n",
    "ppg_span_model.gen_stats().to_csv(\"hddm/ppg_span_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(ppg_span_model.nodes_db.node[['a_ppg_cont', 'v_ppg_cont']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/ppg_span_av_ppg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(ppg_span_model.nodes_db.node[['a_Category[T.1span]', 'a_Category[T.2span]', 'a_Category[T.3span]']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/ppg_span_a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.analyze.plot_posterior_nodes(ppg_span_model.nodes_db.node[['v_Category[T.1span]', 'v_Category[T.2span]', 'v_Category[T.3span]']])\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.savefig('hddm/ppg_span_v.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_span_model.plot_posteriors(['a', 't', 'v', 'a_std'])\n",
    "plt.savefig('hddm/acc_posteriors.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stimulus model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data in correct shape for STIMULUS CODING MODEL\n",
    "# In that case, the ‘resp’ column in your data should contain 0 and 1 for the chosen stimulus (or direction),\n",
    "# not whether the response was correct or not as you would use in accuracy coding.\n",
    "# You then have to provide another column (referred to as stim_col) which contains information about which the correct response was.\n",
    "stim_data = all_data.copy()\n",
    "stim_data = stim_data.rename(columns={\"RESP\": \"response\", \"CRESP\": \"correct_response\"})\n",
    "stim_data = stim_data.replace({'response': {'p': 1, 'q': 0}})\n",
    "stim_data = stim_data.replace({'correct_response': {'p': 1, 'q': 0}})\n",
    "stim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RT distributions\n",
    "stim_data = hddm.utils.flip_errors(stim_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, xlabel='RT', ylabel='count', title='RT distributions')\n",
    "for i, subj_data in stim_data.groupby('subj_idx'):\n",
    "    subj_data.rt.hist(bins=20, histtype='step', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hddm on SET vs noSET responses\n",
    "stim_model = hddm.HDDMStimCoding(stim_data,\n",
    "                                 split_param='v',\n",
    "                                 stim_col='correct_response',\n",
    "                                 depends_on={'a': 'Category', 'v': 'Category'},\n",
    "                                 p_outlier=0.05)\n",
    "stim_model.find_starting_values()\n",
    "stim_model.sample(n_sample, burn=n_burn)\n",
    "stim_model.get_traces().to_csv(\"hddm/stim_traces.csv\")\n",
    "stim_model.gen_stats().to_csv('hddm/stim_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0, a1, a2, a3 = stim_model.nodes_db.node[['a(0span)', 'a(1span)', 'a(2span)', 'a(3span)']]\n",
    "hddm.analyze.plot_posterior_nodes([a0, a1, a2, a3])\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of threshold group means')\n",
    "plt.savefig('hddm/stim_model_a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0, v1, v2, v3 = stim_model.nodes_db.node[['v(0span)', 'v(1span)', 'v(2span)', 'v(3span)']]\n",
    "hddm.analyze.plot_posterior_nodes([v0, v1, v2, v3])\n",
    "plt.xlabel('drift rate')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title('Posterior of drift rate group means')\n",
    "plt.savefig('hddm/stim_model_v.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SETDDM",
   "language": "python",
   "name": "setddm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
